{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7412908-991e-479d-a851-2f08b6fc0509",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import pickle\n",
    "\n",
    "IGNORE_LABEL = 65535  # ADE20K ignore label, it is a left class like a background\n",
    "TARGET_SIZE = (384, 384)  # the final resolution of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfb4617-537d-4fd5-85f7-6a579a5bc2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to resize images\n",
    "def resize_images(source_dir, output_dir, target_size=(384, 384)):\n",
    "   \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    image_files = [f for f in os.listdir(source_dir) \n",
    "                   if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "    \n",
    "    for img_file in tqdm(image_files, desc=\"Resizing images\"):\n",
    "        img_path = os.path.join(source_dir, img_file)\n",
    "        img = cv2.imread(img_path)\n",
    "        \n",
    "        # Resize\n",
    "        img_resized = cv2.resize(img, (target_size[1], target_size[0]))\n",
    "        \n",
    "        # save\n",
    "        output_path = os.path.join(output_dir, img_file)\n",
    "        cv2.imwrite(output_path, img_resized)\n",
    "    \n",
    "#saved in {output_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a234b6-f645-443d-b055-f72b26ca8e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for creation masks for every class \n",
    "def create_full_masks(annotation_dir, output_mask_dir, target_size=(384, 384)):\n",
    "\n",
    "    os.makedirs(output_mask_dir, exist_ok=True)\n",
    "    \n",
    "    json_files = [f for f in os.listdir(annotation_dir) if f.endswith(\".json\")]\n",
    "    \n",
    "    for json_file in tqdm(json_files, desc=\"Creating full masks\"):\n",
    "        json_path = os.path.join(annotation_dir, json_file)\n",
    "        \n",
    "        with open(json_path, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        height = data[\"size\"][\"height\"]\n",
    "        width = data[\"size\"][\"width\"]\n",
    "        \n",
    "        # init mask with ignore(background) label\n",
    "        mask = np.full((height, width), IGNORE_LABEL, dtype=np.uint16)\n",
    "        \n",
    "        # draw every objjects\n",
    "        objects = data.get(\"objects\", [])\n",
    "        objects_sorted = sorted(objects, key=lambda x: x.get(\"area\", 0), reverse=True)\n",
    "        \n",
    "        for obj in objects_sorted:\n",
    "            class_id = obj[\"classId\"]\n",
    "            \n",
    "            # exterior polygon\n",
    "            ext_pts = obj[\"points\"].get(\"exterior\", [])\n",
    "            if len(ext_pts) >= 3:\n",
    "                poly = np.array(ext_pts, dtype=np.int32).reshape((-1, 1, 2))\n",
    "                cv2.fillPoly(mask, [poly], class_id)\n",
    "            \n",
    "            # interior polygons \n",
    "            for int_pts in obj[\"points\"].get(\"interior\", []):\n",
    "                if len(int_pts) >= 3:\n",
    "                    poly = np.array(int_pts, dtype=np.int32).reshape((-1, 1, 2))\n",
    "                    cv2.fillPoly(mask, [poly], IGNORE_LABEL)\n",
    "        \n",
    "        # resize to 384 x 384\n",
    "        mask_resized = cv2.resize(\n",
    "            mask, \n",
    "            (target_size[1], target_size[0]), \n",
    "            interpolation=cv2.INTER_NEAREST\n",
    "        )\n",
    "        \n",
    "        # save as png)\n",
    "        mask_name = json_file.replace(\".json\", \".png\")\n",
    "        cv2.imwrite(os.path.join(output_mask_dir, mask_name), mask_resized)\n",
    "    \n",
    "# saved to {output_mask_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4350c2b3-8870-4e44-898e-b8ee747bca38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pixel distribution analysis after resising masks \n",
    "def analyze_pixel_distribution(mask_dir, ignore_label=65535):\n",
    "\n",
    "    pixel_counter = Counter()\n",
    "    mask_files = sorted([f for f in os.listdir(mask_dir) if f.endswith('.png')])\n",
    "    \n",
    "    for mask_file in tqdm(mask_files, desc=\"Counting pixels\"):\n",
    "        mask_path = os.path.join(mask_dir, mask_file)\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_UNCHANGED)\n",
    "        \n",
    "        if mask is None:\n",
    "            continue\n",
    "        \n",
    "        # counting pixels for every class\n",
    "        unique, counts = np.unique(mask, return_counts=True)\n",
    "        \n",
    "        for class_val, count in zip(unique, counts):\n",
    "            if class_val != ignore_label:\n",
    "                pixel_counter[class_val] += count\n",
    "    \n",
    "    return pixel_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbed420-3598-4083-9488-a87a2534e46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting top N(80%) classes\n",
    "def get_top_percent_classes(pixel_counter, annotation_dir, target_percent=80):\n",
    "    \n",
    "    pixel_counter = {k: v for k, v in pixel_counter.items() \n",
    "                     if k != IGNORE_LABEL}\n",
    "    \n",
    "    if not pixel_counter:\n",
    "        print(\"âš ï¸ Pixel counter Ð¿ÑƒÑÑ‚!\")\n",
    "        return [], {}\n",
    "    \n",
    "    # collecting classId to classTitle\n",
    "    class_titles = {}\n",
    "    json_files = [f for f in os.listdir(annotation_dir) if f.endswith(\".json\")]\n",
    "    \n",
    "    for json_file in tqdm(json_files[:100], desc=\"Building class titles\"):\n",
    "        json_path = os.path.join(annotation_dir, json_file)\n",
    "        with open(json_path, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        for obj in data.get(\"objects\", []):\n",
    "            class_id = obj[\"classId\"]\n",
    "            class_title = obj.get(\"classTitle\", f\"class_{class_id}\")\n",
    "            if class_id != IGNORE_LABEL:\n",
    "                class_titles[class_id] = class_title\n",
    "    \n",
    "    # sorting pixel by pixel\n",
    "    total_pixels = sum(pixel_counter.values())\n",
    "    sorted_classes = sorted(pixel_counter.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    cumulative_pixels = 0\n",
    "    top_classes = []\n",
    "    \n",
    "    for class_id, px_count in sorted_classes:\n",
    "        top_classes.append(class_id)\n",
    "        cumulative_pixels += px_count\n",
    "        if cumulative_pixels / total_pixels >= target_percent / 100:\n",
    "            break\n",
    "    \n",
    "#stats\n",
    "    print(f\"Number of classes in resized datast: {len(pixel_counter)}\")\n",
    "    print(f\"Classes {target_percent}% for pixels: {len(top_classes)}\")\n",
    "    print(f\"Coverage: {cumulative_pixels:,} / {total_pixels:,} of pixels ({cumulative_pixels/total_pixels*100:.2f}%)\")\n",
    "    \n",
    "    print(f\"\\nðŸ“‹ top-{len(top_classes)} clasees:\")\n",
    "    for i, class_id in enumerate(top_classes, 1):\n",
    "        title = class_titles.get(class_id, f\"class_{class_id}\")\n",
    "        px_count = pixel_counter[class_id]\n",
    "        pct = px_count / total_pixels * 100\n",
    "        print(f\"{i:3d}. {class_id:6d} : {title:30s} {px_count:12,} ({pct:6.2f}%)\")\n",
    "    \n",
    "    return top_classes, class_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6a7cec-297d-4196-9674-9e761087bae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating final masks with selected classes \n",
    "def create_filtered_masks(full_mask_dir, output_mask_dir, selected_classes, \n",
    "                         class_id_to_idx, ignore_label=65535):\n",
    "    \n",
    "    os.makedirs(output_mask_dir, exist_ok=True)\n",
    "    \n",
    "    mask_files = sorted([f for f in os.listdir(full_mask_dir) if f.endswith('.png')])\n",
    "        \n",
    "    stats = {'total': 0, 'empty': 0, 'with_objects': 0}\n",
    "    \n",
    "    for mask_file in tqdm(mask_files, desc=\"Creating filtered masks\"):\n",
    "        mask_path = os.path.join(full_mask_dir, mask_file)\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_UNCHANGED)\n",
    "        \n",
    "        # create new mask with new indexes\n",
    "        mask_remapped = np.full_like(mask, 255, dtype=np.uint8)\n",
    "        \n",
    "        objects_found = False\n",
    "        for class_id, new_idx in class_id_to_idx.items():\n",
    "            mask_remapped[mask == class_id] = new_idx\n",
    "            if np.any(mask == class_id):\n",
    "                objects_found = True\n",
    "        \n",
    "        stats['total'] += 1\n",
    "        if objects_found:\n",
    "            stats['with_objects'] += 1\n",
    "        else:\n",
    "            stats['empty'] += 1\n",
    "        \n",
    "        # save\n",
    "        output_path = os.path.join(output_mask_dir, mask_file)\n",
    "        cv2.imwrite(output_path, mask_remapped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68aae5e3-f65f-4b54-ae58-1a9130681638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the main pipeline with calling all functions above\n",
    "DATASET_ROOT = \"./dataset2\" #place where original dataset is located\n",
    "TARGET_PERCENT = 80  # getting 80% of all classes\n",
    "\n",
    "\n",
    "# directories\n",
    "train_img_source = os.path.join(DATASET_ROOT, \"training\", \"img\")\n",
    "train_ann_source = os.path.join(DATASET_ROOT, \"training\", \"ann\")\n",
    "val_img_source = os.path.join(DATASET_ROOT, \"validation\", \"img\")\n",
    "val_ann_source = os.path.join(DATASET_ROOT, \"validation\", \"ann\")\n",
    "\n",
    "# Resized folders\n",
    "resized_root = os.path.join(DATASET_ROOT, \"resized\")\n",
    "train_img_resized = os.path.join(resized_root, \"train\", \"images\")\n",
    "train_mask_full = os.path.join(resized_root, \"train\", \"masks_full\")\n",
    "val_img_resized = os.path.join(resized_root, \"val\", \"images\")\n",
    "val_mask_full = os.path.join(resized_root, \"val\", \"masks_full\")\n",
    "\n",
    "# final folders\n",
    "final_root = os.path.join(DATASET_ROOT, \"processed_final\")\n",
    "train_mask_final = os.path.join(final_root, \"train\", \"masks\")\n",
    "val_mask_final = os.path.join(final_root, \"val\", \"masks\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5736b55-b07e-4bc6-a4b8-19d47c8ba814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# images resizing\n",
    "\n",
    "\n",
    "print(\"\\nTrain images...\")\n",
    "resize_images(train_img_source, train_img_resized, TARGET_SIZE)\n",
    "\n",
    "print(\"\\nValidation images...\")\n",
    "resize_images(val_img_source, val_img_resized, TARGET_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675c5301-2242-49b8-bc45-adc2930bf324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating masks with all classes\n",
    "#Train masks\n",
    "create_full_masks(train_ann_source, train_mask_full, TARGET_SIZE)\n",
    "\n",
    "#Validation masks\n",
    "create_full_masks(val_ann_source, val_mask_full, TARGET_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5d3838-f4f4-4d34-a2ae-ba9f537f8d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_counter = analyze_pixel_distribution(train_mask_full, ignore_label=IGNORE_LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9871a4a-0a25-4e4e-83ad-cb24467ce82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting top 80% of classes\n",
    "selected_classes, class_titles = get_top_percent_classes(\n",
    "    pixel_counter, \n",
    "    train_ann_source, \n",
    "    target_percent=TARGET_PERCENT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bbb14b-4639-4f0b-9895-acedd53bc653",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Creating mappings and sorting it\n",
    "selected_classes_sorted = sorted(selected_classes)\n",
    "class_id_to_idx = {class_id: idx for idx, class_id in enumerate(selected_classes_sorted)}\n",
    "idx_to_class_id = {idx: class_id for class_id, idx in class_id_to_idx.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff2aeda-c082-43d8-81da-3df63e867234",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train masks\n",
    "create_filtered_masks(train_mask_full, train_mask_final, selected_classes, \n",
    "                     class_id_to_idx, IGNORE_LABEL)\n",
    "\n",
    "#Validation masks\n",
    "create_filtered_masks(val_mask_full, val_mask_final, selected_classes, \n",
    "                     class_id_to_idx, IGNORE_LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9356f953-3c35-4c43-8b17-0b78df084b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving mappings\n",
    "mappings = {\n",
    "    'selected_classes': selected_classes_sorted,\n",
    "    'class_titles': class_titles,\n",
    "    'class_id_to_idx': class_id_to_idx,\n",
    "    'idx_to_class_id': idx_to_class_id,\n",
    "    'num_classes': len(selected_classes_sorted),\n",
    "    'target_size': TARGET_SIZE,\n",
    "    'target_percent': TARGET_PERCENT\n",
    "}\n",
    "#sacing mappings\n",
    "mappings_path = os.path.join(DATASET_ROOT, \"class_mappings_final.pkl\")\n",
    "with open(mappings_path, \"wb\") as f:\n",
    "    pickle.dump(mappings, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a497e497-8685-40a5-9a88-cbafc08944db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# images: resized/train(val)/images\n",
    "#m asks:  processed_final/train(val)/masks\n",
    "\n",
    "#Train: ./dataset2\\resized\\train\\images\n",
    "#     Val:   ./dataset2\\resized\\val\\images\n",
    "\n",
    "#   final msaks (with 0-13 mapping):\n",
    "#     Train: ./dataset2\\processed_final\\train\\masks\n",
    "#     Val:   ./dataset2\\processed_final\\val\\masks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
